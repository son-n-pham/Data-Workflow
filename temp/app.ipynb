{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1012 entries, 1 to 1012\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   DEPMD          1010 non-null   float64\n",
      " 1   WOB_AVG        1010 non-null   float64\n",
      " 2   DEPTVD         1010 non-null   float64\n",
      " 3   ROPA_AVG       1010 non-null   float64\n",
      " 4   TORQ_AVG       1010 non-null   float64\n",
      " 5   SURFRPM_AVG    1010 non-null   float64\n",
      " 6   MOTORRPM_AVG   1010 non-null   float64\n",
      " 7   BITRPM_AVG     1010 non-null   float64\n",
      " 8   SPP_AVG        1010 non-null   float64\n",
      " 9   CHKP_AVG       1010 non-null   float64\n",
      " 10  CEMENTP_AVG    1010 non-null   float64\n",
      " 11  SPM01_AVG      1010 non-null   float64\n",
      " 12  SPM02_AVG      1010 non-null   float64\n",
      " 13  SPM03_AVG      1010 non-null   float64\n",
      " 14  PITACTIVE_AVG  1010 non-null   float64\n",
      " 15  FLOWIN_AVG     1010 non-null   float64\n",
      " 16  FLOWOUTP_AVG   1010 non-null   float64\n",
      " 17  DIN_AVG        1010 non-null   float64\n",
      " 18  TIN_AVG        1010 non-null   float64\n",
      " 19  DOUT_AVG       1010 non-null   float64\n",
      " 20  TOUT_AVG       1010 non-null   float64\n",
      " 21  HHP            1010 non-null   float64\n",
      " 22  Comments       0 non-null      float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 182.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    DEPMD  WOB_AVG   DEPTVD  ROPA_AVG  TORQ_AVG  SURFRPM_AVG  MOTORRPM_AVG  \\\n",
       " 1  567.0    12.31  2533.49    141.86      4.87         48.0           0.0   \n",
       " 2  568.0     2.51  2534.33     90.56      4.78         48.0           0.0   \n",
       " 3  569.0     3.21  2535.19     80.75      4.57         48.0           0.0   \n",
       " 4  570.0     3.10  2536.04     89.63      4.61         48.0           0.0   \n",
       " 5  571.0     3.68  2536.87     54.78      4.54         48.0           0.0   \n",
       " \n",
       "    BITRPM_AVG  SPP_AVG  CHKP_AVG  ...  SPM03_AVG  PITACTIVE_AVG  FLOWIN_AVG  \\\n",
       " 1        48.0    689.0       0.0  ...        0.0        227.124       510.0   \n",
       " 2        48.0    685.0       0.0  ...        0.0        227.451       511.0   \n",
       " 3        48.0    689.0       0.0  ...        0.0        227.216       510.0   \n",
       " 4        48.0    685.0       0.0  ...        0.0        227.619       511.0   \n",
       " 5        48.0    676.0       0.0  ...        0.0        228.554       514.0   \n",
       " \n",
       "    FLOWOUTP_AVG  DIN_AVG  TIN_AVG  DOUT_AVG  TOUT_AVG        HHP  Comments  \n",
       " 1         24.11    11.69   37.954     11.69      34.7  44.508759       NaN  \n",
       " 2         23.78    11.69   37.963     11.69      34.7  43.686215       NaN  \n",
       " 3         24.61    11.69   37.948     11.69      34.8  41.766946       NaN  \n",
       " 4         23.37    11.69   37.923     11.69      34.7  42.132521       NaN  \n",
       " 5         24.95    11.69   38.025     11.69      34.7  41.492765       NaN  \n",
       " \n",
       " [5 rows x 23 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"./data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Remove the first row containing units (now index 0 after reading the file)\n",
    "df = df.drop(index=0)\n",
    "\n",
    "# Convert all columns to numeric types, errors='coerce' will replace non-convertible values with NaN\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Display the cleaned dataframe and data types\n",
    "df.info(), df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count     1010.000000\n",
       " mean     18182.367216\n",
       " std       8983.546005\n",
       " min          0.000000\n",
       " 25%      11825.114865\n",
       " 50%      17910.101057\n",
       " 75%      23584.131339\n",
       " max      90190.017744\n",
       " Name: MSE, dtype: float64,\n",
       " 1    51475.794130\n",
       " 2    16137.683771\n",
       " 3    22128.638707\n",
       " 4    19421.609577\n",
       " 5    37149.899249\n",
       " Name: MSE, dtype: float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Constants for conversion\n",
    "inches_to_feet = 1 / 12\n",
    "bit_diameter_in = 8.5  # Bit size in inches\n",
    "\n",
    "# Calculate the cross-sectional area in square feet\n",
    "AREA_sqft = (np.pi / 4) * (bit_diameter_in * inches_to_feet) ** 2\n",
    "\n",
    "# Since MOTORRPM_AVG is all zeros, we'll assume BITRPM_AVG as RPM for MSE calculation\n",
    "# Convert TORQ_AVG from kLbf.ft to Lbf.ft for MSE calculation\n",
    "df['TORQ_AVG_Lbf.ft'] = df['TORQ_AVG'] * 1000\n",
    "\n",
    "# Calculate MSE using the given formula\n",
    "df['MSE'] = (df['WOB_AVG'] * df['BITRPM_AVG'] *\n",
    "             df['TORQ_AVG_Lbf.ft']) / (df['ROPA_AVG'] * AREA_sqft)\n",
    "\n",
    "# Check if MSE calculation makes sense by looking at its statistics and first few values\n",
    "mse_stats = df['MSE'].describe()\n",
    "mse_head = df['MSE'].head()\n",
    "\n",
    "mse_stats, mse_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bins must increase monotonically.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m bin_labels_iqr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVery Low HHP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow HHP\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedium HHP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh HHP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVery High HHP\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Assign HHP data to bins\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHHP_Bin_IQR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcut\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHHP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbin_edges_iqr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbin_labels_iqr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_lowest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Display the bin edges and the first few entries of the dataframe to verify\u001b[39;00m\n\u001b[1;32m     17\u001b[0m bin_edges_iqr, df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHHP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHHP_Bin_IQR\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/miniconda3/envs/deep_learning/lib/python3.10/site-packages/pandas/core/reshape/tile.py:291\u001b[0m, in \u001b[0;36mcut\u001b[0;34m(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# GH 26045: cast to float64 to avoid an overflow\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mdiff(bins\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 291\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbins must increase monotonically.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m fac, bins \u001b[38;5;241m=\u001b[39m _bins_to_cuts(\n\u001b[1;32m    294\u001b[0m     x,\n\u001b[1;32m    295\u001b[0m     bins,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m     ordered\u001b[38;5;241m=\u001b[39mordered,\n\u001b[1;32m    303\u001b[0m )\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _postprocess_for_cut(fac, bins, retbins, dtype, original)\n",
      "\u001b[0;31mValueError\u001b[0m: bins must increase monotonically."
     ]
    }
   ],
   "source": [
    "# Calculate the first quartile (Q1) and third quartile (Q3) for HHP\n",
    "Q1 = df['HHP'].quantile(0.25)\n",
    "Q3 = df['HHP'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bin edges based on IQR\n",
    "bin_edges_iqr = [df['HHP'].min(), Q1 - 1.5 * IQR, Q1, Q3,\n",
    "                 Q3 + 1.5 * IQR, df['HHP'].max()]\n",
    "bin_labels_iqr = ['Very Low HHP', 'Low HHP',\n",
    "                  'Medium HHP', 'High HHP', 'Very High HHP']\n",
    "\n",
    "# Assign HHP data to bins\n",
    "df['HHP_Bin_IQR'] = pd.cut(\n",
    "    df['HHP'], bins=bin_edges_iqr, labels=bin_labels_iqr, include_lowest=True)\n",
    "\n",
    "# Display the bin edges and the first few entries of the dataframe to verify\n",
    "bin_edges_iqr, df[['HHP', 'HHP_Bin_IQR']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQR: 12.509520182787512\n",
      "Q1: 72.82939832444782\n",
      "Q3: 85.33891850723533\n",
      "Bin Edges: [0.0, 54.065118050266555, 72.82939832444782, 85.33891850723533, 104.10319878141661, 101.2947448591013]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the first quartile (Q1) and third quartile (Q3) for HHP\n",
    "Q1 = df['HHP'].quantile(0.25)\n",
    "Q3 = df['HHP'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Display the IQR and quartiles\n",
    "print(\"IQR:\", IQR)\n",
    "print(\"Q1:\", Q1)\n",
    "print(\"Q3:\", Q3)\n",
    "\n",
    "# Define the lower and upper bounds for the bins\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Define the bin edges\n",
    "bin_edges = [df['HHP'].min(), lower_bound, Q1, Q3, upper_bound, df['HHP'].max()]\n",
    "\n",
    "# Display the bin edges\n",
    "print(\"Bin Edges:\", bin_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 54.065118050266555, 72.82939832444782, 85.33891850723533, 104.10319878141661, 101.2947448591013]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Q1 and Q3 using the quantile function\n",
    "Q1 = df['HHP'].quantile(0.25)\n",
    "Q3 = df['HHP'].quantile(0.75)\n",
    "\n",
    "# Calculate the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for the bins\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Define the bin edges\n",
    "bin_edges = [lower_bound, Q1, Q3, upper_bound]\n",
    "\n",
    "print(bin_edges)\n",
    "\n",
    "# Assign data to bins using pd.cut\n",
    "df['HHP_Bin'] = pd.cut(df['HHP'], bins=bin_edges, labels=['Very Low HHP', 'Low HHP', 'Medium HHP', 'High HHP', 'Very High HHP'])\n",
    "\n",
    "# Create a scatter plot of MSE vs ROP with different colors for each HHP bin\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = {'Very Low HHP': 'red', 'Low HHP': 'orange', 'Medium HHP': 'yellow', 'High HHP': 'green', 'Very High HHP': 'blue'}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for label, color in colors.items():\n",
    "    subset = df[df['HHP_Bin'] == label]\n",
    "    ax.scatter(subset['ROP_AVG'], subset['MSE'], label=label, color=color)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.xlabel('ROP_AVG')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from ipywidgets import widgets, interactive\n",
    "\n",
    "# Example data\n",
    "x = [1, 2, 3, 4]\n",
    "y = [10, 11, 12, 13]\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.FigureWidget([go.Scatter(x=x, y=y, mode='markers')])\n",
    "\n",
    "# Function to update the plot\n",
    "\n",
    "\n",
    "def update_plot(comment, x_value, y_value):\n",
    "    with fig.batch_update():\n",
    "        fig.data[0].x = x\n",
    "        fig.data[0].y = y\n",
    "        fig.add_annotation(x=x_value, y=y_value, text=comment,\n",
    "                           showarrow=True, arrowhead=1)\n",
    "\n",
    "\n",
    "# Create widgets\n",
    "comment_text = widgets.Text(value='Comment', description='Comment:')\n",
    "x_value = widgets.FloatSlider(value=1, min=min(\n",
    "    x), max=max(x), description='X Value:')\n",
    "y_value = widgets.FloatSlider(value=10, min=min(\n",
    "    y), max=max(y), description='Y Value:')\n",
    "\n",
    "# Display widgets and plot\n",
    "interactive(update_plot, comment=comment_text,\n",
    "            x_value=x_value, y_value=y_value)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
